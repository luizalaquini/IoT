{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGCwhCOx_9BR"
      },
      "source": [
        "<h1><center>Internet das Coisas – 2023/1\n",
        "\n",
        "Prof. Vinícius Mota\n",
        "\n",
        "\n",
        "Laboratório – Aprendizado Federado usando a biblioteca Flower\n",
        "\n",
        "Roteiro elaborado por: Eduardo Sarmento (Mestrando 2022/2)\n",
        "\n",
        "</h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfbB0PxwAq-q"
      },
      "source": [
        "<u>Objetivo</u>:\\\n",
        "Experimentar o treinamento de modelos de aprendizado de máquina por meio do *framework* de aprendizado *flwr*, disponível na biblioteca *flower* Comparar os resultados atingidos pelo modelo treinado de maneira local e federada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh8VLSKIFsFV"
      },
      "source": [
        "Este roteiro de laboratório foi testado usando o [Google Colab](https://colab.research.google.com/), ambiente de desenvolvimento colaborativo Python disponibilizado pelo Google como um serviço em nuvem.\\\n",
        "\\\n",
        "Para a execução do código deste roteiro são necessárias as bibliotecas *tensorflow* (versão 2.12.0), *numpy* (versão 1.22.4), *ray* (versão 2.2.0), *matplotlib* (versão 3.7.1) e *flower* (versão 1.3.0). As quatro primeiras já vem instaladas no **Google Colab**,. ntão, caso esteja executando por ele, não é necessária sua instalação. A biblioteca flower não vem instalada,  então precisamos instalá-la, e também o seu módulo de simulação, para podermos simular o treinamento federado no *notebook*."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A célula seguinte executa a instalação de todas as bibliotecas necessárias. Caso esteja fora do Colab, é preciso descomentar as linhas de 3 a 5."
      ],
      "metadata": {
        "id": "CzNS6Vh14t8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5l58I7JhXc",
        "outputId": "1e3d0736-f67a-4afa-90ee-769c394e64f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr==1.3.0\n",
            "  Downloading flwr-1.3.0-py3-none-any.whl (139 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.43.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.3.0) (1.56.0)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr==1.3.0)\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.3.0) (3.20.3)\n",
            "Installing collected packages: iterators, flwr\n",
            "Successfully installed flwr-1.3.0 iterators-0.0.2\n",
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Collecting flwr[simulation]\n",
            "  Downloading flwr-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.56.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (3.20.3)\n",
            "Collecting ray[default]<3.0.0,>=2.3.0 (from flwr[simulation])\n",
            "  Downloading ray-2.5.1-cp310-cp310-manylinux2014_x86_64.whl (56.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (3.12.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (2.27.1)\n",
            "Collecting grpcio!=1.52.0,<2.0.0,>=1.48.2 (from flwr[simulation])\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (3.8.4)\n",
            "Collecting aiohttp-cors (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0 (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0 (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.10.9)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (0.17.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (6.3.0)\n",
            "Collecting virtualenv<20.21.1,>=20.0.24 (from ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.9.2)\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0->ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading nvidia_ml_py-11.525.131-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (5.9.5)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0->ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv<20.21.1,>=20.0.24->ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.10/dist-packages (from virtualenv<20.21.1,>=20.0.24->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (0.19.3)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (3.4)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (1.59.1)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (2.17.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3.0.0,>=2.3.0->flwr[simulation]) (0.5.0)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26280 sha256=7b4d60e02bbad7317b86e661537b6f9f48c6fdb6d668b5414bbbb80e95d1a6c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d0/2c/1e02440645c2318ba03aea99993a44a9108dc8f74de0bd370b\n",
            "Successfully built gpustat\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py, distlib, colorful, virtualenv, grpcio, blessed, ray, gpustat, flwr, aiohttp-cors, opencensus\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.56.0\n",
            "    Uninstalling grpcio-1.56.0:\n",
            "      Successfully uninstalled grpcio-1.56.0\n",
            "  Attempting uninstall: flwr\n",
            "    Found existing installation: flwr 1.3.0\n",
            "    Uninstalling flwr-1.3.0:\n",
            "      Successfully uninstalled flwr-1.3.0\n",
            "Successfully installed aiohttp-cors-0.7.0 blessed-1.20.0 colorful-0.5.5 distlib-0.3.6 flwr-1.4.0 gpustat-1.1 grpcio-1.51.3 nvidia-ml-py-11.525.131 opencensus-0.11.2 opencensus-context-0.1.3 py-spy-0.3.14 ray-2.5.1 virtualenv-20.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr==1.3.0\n",
        "!pip install -U flwr[\"simulation\"]\n",
        "#!pip install ray==2.2.0\n",
        "#!pip install tensorflow==2.12.0\n",
        "#!pip install numpy==1.22.4\n",
        "#!pip install matplotlib==3.7.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Célula de Importação"
      ],
      "metadata": {
        "id": "Xt4gBsQ7VYUA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wD8STHmJcZZ"
      },
      "source": [
        "Importamos a biblioteca *os*, que lida com o sistema operacional. Utilizamos ela para configurar a *flag* \"TF_CPP_MIN_LOG_LEVEL\" com o valor 3, isto faz com que os logs do *tensorflow* sejam menos verbosos durante o treinamento.\\\n",
        "Depois, importamos as demais bibliotecas:\n",
        "\n",
        "1.   *flower*, para efetuar o aprendizado federado;\n",
        "2.   *tensorflow*, para definir uma arquitetura de rede neural, incluindo todas as camadas e otimizador que usaremos;\n",
        "3.   *numpy*, biblioteca de maniupulação eficiente de vetores numéricos;\n",
        "4.   *ray*, biblioteca utilizada pelo *flower* para instanciar a simulação do aprendizado federado.\n",
        "5.   *matplotlib*, biblioteca para plotar gráficos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dwfd_R6JSkE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Make TensorFlow logs less verbose\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import flwr as fl\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D,Flatten,Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import ray\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMrrg_-wTSSg"
      },
      "source": [
        "#### Importação e Pré-rocessamento dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpgFLN0YGu2P"
      },
      "source": [
        "Neste laboratório usaremos o *dataset* MNIST, muito usado como referência na literatura. Este *dataset* é composto por imagens monocromáticas de 28 por 28 píxels (*28x28*), representando dígitos de 0 a 9 escritos a mão e anotadas com o valor do dígito. Ele contém dois *subdatasets*: o de treino e o de teste. O *subdataset* de treino é formado por 60 mil imagens, enquanto o *subdataset* de teste contém 10 mil imagens.\n",
        "\n",
        "O *tensorflow* já nos provê esse *dataset*, separando os *subdatasets* de treino entre: atributos alvo, tambem chamados de classes ou *targets* (*y_train e y_test*), e atributos não alvo (*x_train* e *x_test*), ou *features*. Sendo assim, para carregar este *dataset* basta instanciar (atribuição da variavel *mnist*) e carregar (método *load_data*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh4cJYFwJuWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296f3929-ca26-4561-dbfe-ef095837f57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotamos, como exemplo, os 10 primeiros dígitos do *dataset* de treino com suas classes. Por meio desse *plot* conseguiremos visualizar bem o tipo de dado que o *dataset* descreve.\n",
        "\n",
        " Vemos que as classes são o valor numérico que o dígito representa e as imagens são dígitos escritos a mão, em preto e branco."
      ],
      "metadata": {
        "id": "7bhElqYx8io1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = 10\n",
        "images = x_train[:num]\n",
        "labels = y_train[:num]\n",
        "num_row = 2\n",
        "num_col = 5\n",
        "# plot images\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "YqbYR3v-7DyU",
        "outputId": "aa80628b-1dd7-4f14-a0ac-7afdbe1ab9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x400 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAFrCAYAAACZqpz1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKv0lEQVR4nO3dfXzN9f/H8dfGrjCbYZvFXEThS+rrYiahrBZJROhbpJTKCKWkC3S5KCUXSRdIF19FRvn2rXxdlZqJvvp+F5ZEiM2kXbjasPfvj+/Pp/P+7Oqc7XP2Oefscb/dzu32fp3355zzdva0vffZ+7w/fkopJQAAAABs4W/3AAAAAIDqjAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANiICTkAAABgIybkAAAAgI2YkAMAAAA2YkIOAAAA2IgJeQXs379f/Pz85KWXXrLsOTdu3Ch+fn6yceNGy54Tno8swSpkCVYgR7ASeXJetZmQL1myRPz8/GTbtm12D8Utpk+fLn5+fsVuwcHBdg/N5/h6lkREfvvtNxkyZIiEh4dL3bp15aabbpJffvnF7mH5nOqQJUfXXnut+Pn5ydixY+0eik/x9RxlZGTIxIkTpVu3bhIcHCx+fn6yf/9+u4fls3w9TyIiy5Ytk7/+9a8SHBwsDRs2lFGjRsmxY8dsHVNNW18dlluwYIHUqVPHqGvUqGHjaOCNTpw4IVdffbXk5ubKY489JgEBAfLKK69Iz549ZceOHVK/fn27hwgvtHLlSklNTbV7GPBCqampMmfOHGnbtq20adNGduzYYfeQ4MUWLFggY8aMkd69e8vLL78shw4dkldffVW2bdsmaWlptp3IZELuYwYPHiwNGjSwexjwYq+99prs2bNHtm7dKp07dxYRkT59+ki7du1k1qxZ8vzzz9s8QnibM2fOyEMPPSSTJ0+WqVOn2j0ceJn+/ftLTk6OhIaGyksvvcSEHBVWWFgojz32mPTo0UPWrl0rfn5+IiLSrVs3ufHGG+XNN9+UcePG2TK2arNkxRmFhYUydepU6dixo4SFhUnt2rXlqquukg0bNpT6mFdeeUWaNm0qISEh0rNnT0lPTy92zO7du2Xw4MESEREhwcHB0qlTJ/nkk0/KHc+pU6dk9+7dLv0ZRSkleXl5opRy+jGwnjdnacWKFdK5c2djMi4i0rp1a+ndu7d89NFH5T4e1vLmLF0wc+ZMKSoqkkmTJjn9GFjLm3MUEREhoaGh5R6HquOteUpPT5ecnBwZOnSoMRkXEenXr5/UqVNHli1bVu5ruQsTcgd5eXny1ltvSa9evWTGjBkyffp0yc7OlsTExBJ/I1+6dKnMmTNHkpKSZMqUKZKeni7XXHONZGVlGcf8+OOP0rVrV9m1a5c8+uijMmvWLKldu7YMGDBAUlJSyhzP1q1bpU2bNjJv3jyn/w0tWrSQsLAwCQ0Nldtvv10bC6qOt2apqKhI/vOf/0inTp2K9XXp0kX27t0r+fn5zr0JsIS3ZumCAwcOyAsvvCAzZsyQkJAQl/7tsI635wiexVvzVFBQICJS4veikJAQ+fe//y1FRUVOvANuoKqJxYsXKxFR3333XanHnDt3ThUUFGj3/fHHHyoqKkrdddddxn379u1TIqJCQkLUoUOHjPvT0tKUiKiJEyca9/Xu3Vu1b99enTlzxrivqKhIdevWTbVq1cq4b8OGDUpE1IYNG4rdN23atHL/fbNnz1Zjx45V77//vlqxYoUaP368qlmzpmrVqpXKzc0t9/Fwni9nKTs7W4mIevrpp4v1zZ8/X4mI2r17d5nPAef5cpYuGDx4sOrWrZtRi4hKSkpy6rFwTnXI0QUvvviiEhG1b98+lx4H5/lynrKzs5Wfn58aNWqUdv/u3buViCgRUceOHSvzOdyFM+QOatSoIYGBgSLyvzOFx48fl3PnzkmnTp3k+++/L3b8gAED5KKLLjLqLl26SFxcnHz22WciInL8+HFZv369DBkyRPLz8+XYsWNy7Ngx+f333yUxMVH27Nkjv/32W6nj6dWrlyilZPr06eWOffz48TJ37lz529/+JoMGDZLZs2fLO++8I3v27JHXXnvNxXcCleWtWTp9+rSIiAQFBRXru/BBlwvHoGp4a5ZERDZs2CAff/yxzJ4927V/NCznzTmC5/HWPDVo0ECGDBki77zzjsyaNUt++eUX+frrr2Xo0KESEBAgIvb9jGNCbvLOO+/IZZddJsHBwVK/fn1p2LCh/OMf/5Dc3Nxix7Zq1arYfZdccomxHdPPP/8sSil58sknpWHDhtpt2rRpIiJy9OhRt/1b/va3v0l0dLT861//cttroHTemKULf8a78Gc9R2fOnNGOQdXxxiydO3dOHnjgARk+fLj2eQTYxxtzBM/lrXlauHCh9O3bVyZNmiQXX3yx9OjRQ9q3by833nijiIi2U11VYpcVB++9956MHDlSBgwYIA8//LBERkZKjRo1JDk5Wfbu3evy811YhzRp0iRJTEws8ZiWLVtWaszladKkiRw/ftytr4HivDVLEREREhQUJEeOHCnWd+G+mJiYSr8OnOetWVq6dKlkZGTIwoULi+0ZnZ+fL/v375fIyEipVatWpV8L5fPWHMEzeXOewsLCZPXq1XLgwAHZv3+/NG3aVJo2bSrdunWThg0bSnh4uCWv4yom5A5WrFghLVq0kJUrV2qfvr3w25nZnj17it33008/SbNmzUTkfx+wFBEJCAiQhIQE6wdcDqWU7N+/X6644ooqf+3qzluz5O/vL+3bty/xghBpaWnSokULdjuoYt6apQMHDsjZs2flyiuvLNa3dOlSWbp0qaSkpMiAAQPcNgb8yVtzBM/kC3mKjY2V2NhYERHJycmR7du3y6BBg6rktUvCkhUHFy6ioxy2DExLSyv1YharVq3S1jRt3bpV0tLSpE+fPiIiEhkZKb169ZKFCxeWeMYxOzu7zPG4si1USc+1YMECyc7Oluuvv77cx8Na3pylwYMHy3fffadNyjMyMmT9+vVyyy23lPt4WMtbszRs2DBJSUkpdhMR6du3r6SkpEhcXFyZzwHreGuO4Jl8LU9TpkyRc+fOycSJEyv0eCtUuzPkixYtks8//7zY/ePHj5d+/frJypUrZeDAgXLDDTfIvn375PXXX5e2bdvKiRMnij2mZcuW0r17d7n//vuloKBAZs+eLfXr15dHHnnEOGb+/PnSvXt3ad++vdxzzz3SokULycrKktTUVDl06JD88MMPpY5169atcvXVV8u0adPK/aBC06ZNZejQodK+fXsJDg6WzZs3y7Jly+Tyyy+Xe++91/k3CE7z1SyNGTNG3nzzTbnhhhtk0qRJEhAQIC+//LJERUXJQw895PwbBKf5YpZat24trVu3LrGvefPmnBl3A1/MkYhIbm6uzJ07V0REvvnmGxERmTdvnoSHh0t4eLiMHTvWmbcHLvLVPL3wwguSnp4ucXFxUrNmTVm1apV8+eWX8uyzz9r7eZeq39jFHhe28SntdvDgQVVUVKSef/551bRpUxUUFKSuuOIKtWbNGnXHHXeopk2bGs91YRufF198Uc2aNUs1adJEBQUFqauuukr98MMPxV577969asSIESo6OloFBASoiy66SPXr10+tWLHCOKay20Ldfffdqm3btio0NFQFBASoli1bqsmTJ6u8vLzKvG0oga9nSSmlDh48qAYPHqzq1q2r6tSpo/r166f27NlT0bcMpagOWTITtj20nK/n6MKYSro5jh3W8PU8rVmzRnXp0kWFhoaqWrVqqa5du6qPPvqoMm+ZJfyU4pKOAAAAgF1YQw4AAADYiAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANjIbRPy+fPnS7NmzSQ4OFji4uJk69at7nop+DiyBKuQJViFLMEqZAkiIm7Z9vDDDz+UESNGyOuvvy5xcXEye/ZsWb58uWRkZEhkZGSZjy0qKpLDhw9LaGiodjlWeA6llOTn50tMTIz4+7v3jyxkybeRJViFLMEqZAlWcSlL7tjcvEuXLtqFH86fP69iYmJUcnJyuY89ePBgmRvSc/Oc28GDB90RHw1Zqh43ssSNLHHztBtZ4laVWbL8V7/CwkLZvn27JCQkGPf5+/tLQkKCpKamFju+oKBA8vLyjJviOkVeIzQ01K3PT5aqD7IEq5AlWIUswSrOZMnyCfmxY8fk/PnzEhUVpd0fFRUlmZmZxY5PTk6WsLAw4xYbG2v1kOAm7v4TGVmqPsgSrEKWYBWyBKs4kyXbd1mZMmWK5ObmGreDBw/aPSR4KbIEq5AlWIUswSpkybfVtPoJGzRoIDVq1JCsrCzt/qysLImOji52fFBQkAQFBVk9DPgAsgSrkCVYhSzBKmQJjiw/Qx4YGCgdO3aUdevWGfcVFRXJunXrJD4+3uqXgw8jS7AKWYJVyBKsQpagqegng8uybNkyFRQUpJYsWaJ27typRo8ercLDw1VmZma5j83NzbX907DcnLvl5ua6Iz5kqRreyBI3ssTN025kiVtVZsktE3KllJo7d66KjY1VgYGBqkuXLmrLli1OPY6Aec+tKr5ZKUWWqsONLHEjS9w87UaWuFVlltxyYaDKyMvLk7CwMLuHASfk5uZK3bp17R5GqciS9yBLsApZglXIEqziTJZs32UFAAAAqM6YkAMAAAA2YkIOAAAA2IgJOQAAAGAjJuQAAACAjZiQAwAAADaqafcAAFRcx44dtXrs2LFaPWLECKO9dOlSrW/u3Lla/f3331s8OgAA4AzOkAMAAAA2YkIOAAAA2IgJOQAAAGAj1pBbpEaNGlrtyuVszet+a9WqZbQvvfRSrS8pKUmrX3rpJa2+9dZbjfaZM2e0vhdeeEGrn3rqKafHCM9w+eWXa/XatWu12nxpXqWU0R4+fLjW179/f62uX7++BSMERHr37q3V77//vtHu2bOn1peRkVElY4JneuKJJ7Ta/HPJ318/b9irVy+jvWnTJreNC6hqnCEHAAAAbMSEHAAAALARS1YcxMbGanVgYKDR7tatm9bXvXt3rQ4PD9fqQYMGWTKmQ4cOafWcOXO0euDAgVqdn59vtH/44Qetjz/veacuXboY7Y8//ljrMy+NclyiIqLnobCwUOszL1Hp2rWrVjtug2h+LFzTo0cPrXZ871NSUqp6OG7XuXNnrf7uu+9sGgk80ciRI4325MmTtb6ioqIyH2v+Hgf4Cs6QAwAAADZiQg4AAADYiAk5AAAAYKNqvYbcvIXc+vXrtdqVrQut5LiGzrwl1IkTJ7TacTsxEZEjR44Y7T/++EPrY3sxz+S4zaWIyF//+letfu+994x2o0aNXHruPXv2GO2ZM2dqfcuWLdPqb775Rqsds5ecnOzS60LnuFWbiEirVq2Mti+sITdvTde8eXOtbtq0qdH28/OrkjHBcznmITg42MaRwA5xcXFaffvttxtt87aof/nLX8p8rkmTJhntw4cPa33mz/o5/iwVEUlLSyt/sFWIM+QAAACAjZiQAwAAADZiQg4AAADYqFqvIT9w4IBW//7771pt1Rpy8zqlnJwcrb766qu12nHP53fffdeSMcBzLVy4UKtvvfVWy57bcT16nTp1tD7zvvTmdc6XXXaZZeOo7kaMGKHVqampNo3EPcyfbbjnnnu02nHt5u7du6tkTPAcCQkJWj1u3LhSjzXno1+/flqdlZVl3cBQJYYOHarVr776qlY3aNDAaJs/Y7Jx40atbtiwoVa/+OKLpb6u+bnMjx02bFipj7UDZ8gBAAAAGzEhBwAAAGzEhBwAAACwUbVeQ378+HGtfvjhh7Xace3av//9b61vzpw5ZT73jh07jPa1116r9Z08eVKrzftsjh8/vsznhnfr2LGjVt9www1aXdY+zeZ1359++qlWv/TSS1rtuC+rOcPmfeqvueYap8cB15j36fY1b731Vpn9jvvhw/eZ939evHixVpf1+SzzmuBff/3VuoHBbWrW/HM62alTJ63vzTff1GrztTe++uoro/3MM89ofZs3b9bqoKAgrf7oo4+M9nXXXVfmGLdt21Zmv91c/inx1VdfyY033igxMTHi5+cnq1at0vqVUjJ16lRp1KiRhISESEJCAt+MUSKyBKuQJViFLMEqZAmucHlCfvLkSenQoYPMnz+/xP6ZM2fKnDlz5PXXX5e0tDSpXbu2JCYmypkzZyo9WPgWsgSrkCVYhSzBKmQJrvBTSqkKP9jPT1JSUmTAgAEi8r/f9mJiYuShhx4yLmeam5srUVFRsmTJEqe2mMnLy7PtkvVmdevWNdr5+flan3mrulGjRmm146Vg//73v7thdPbLzc3V3qPK8PUsXX755UZ7/fr1Wl957+E///lPo23eEtF8mWHzVoWOSwmys7PLfJ3z589r9alTp0p9ne+//77M53KVr2XJ/HUwb3O4cuVKoz18+HCnn9dTffvtt1rdtWtXre7WrZvR3rJli1vH4mtZ8kbmJQp33XVXqceat7Xr3bu3O4ZUIWTJeSNHjjTa5S1hW7t2rVY7bouYl5dX5mMd51YiIkuWLCn12N9++02rzUtpyvuZaCVnsmTpwsZ9+/ZJZmamtudoWFiYxMXFlbrvbkFBgeTl5Wk3gCzBKmQJViFLsApZgpmlE/LMzEwREYmKitLuj4qKMvrMkpOTJSwszLg1adLEyiHBS5ElWIUswSpkCVYhSzCz/aP/U6ZMkdzcXON28OBBu4cEL0WWYBWyBKuQJViFLPk2S7c9jI6OFpH/XdrW8VLKWVlZ2hpaR0FBQcW2sfEUZf05KDc3t8zHOl46+sMPP9T6ioqKKjewasDbs3TJJZdoteOWmuY1f8eOHdPqI0eOaPU777xjtE+cOKH1/eMf/yizroyQkBCj/dBDD2l9t912m2Wv4252ZKlv375a7fhe+gLzWb3mzZuXebx5Lae38vbvS+7ieOlzkeJrxs0/83Jycoz2s88+67ZxeTJvz5J5e8LHHnvMaJs/mvjaa69p9RNPPKHVriy9efzxx50+9oEHHtDqqlwzXhGWniFv3ry5REdHy7p164z78vLyJC0tTeLj4618Kfg4sgSrkCVYhSzBKmQJZi6fIT9x4oT8/PPPRr1v3z7ZsWOHRERESGxsrEyYMEGeffZZadWqlTRv3lyefPJJiYmJMT5ZDFxAlmAVsgSrkCVYhSzBFS5PyLdt2yZXX321UT/44IMiInLHHXfIkiVL5JFHHpGTJ0/K6NGjJScnR7p37y6ff/65BAcHWzdq+ASyBKuQJViFLMEqZAmuqNQ+5O7gSftqlqV27dpabb6EueO+zX369NH6vvzyS/cNrApZuUerO1Rllszr+pYvX67VjmuKzevAHfdgFSl+eV/H9ceHDh2q1DjLYt6H3PFbg3kbrquuusrS1/a1LJkvFX7HHXdoteN6yxdeeKFyg7PBu+++q9XmzxT89NNPWu24L7nj+mF38LUseapmzZoZ7Y8//ljrM6+BNq8hd1x//PTTT1s+NquQpT9NnTpVq6dNm6bVhYWFRvuLL77Q+szXzzh9+nSpr2P+ZeS6667TavN1XRyPN38ewTxGO1X5PuQAAAAAXMOEHAAAALARE3IAAADARpbuQ16dnDx5Uqsd9x0XEfn++++N9ptvvqn1bdiwQavNa4bnz59vtD1siT9KccUVV2i1eR9qRzfddJNWb9q0yS1jguf67rvv7B5CMeb1jddff71W33777UbbvK7TzLxHsbvXjaPqOebjsssuK/NYx639REReffVVt4wJ1gkPD9fqMWPGaLV5buK4btzVXWJatmxptN9//32tr2PHjmU+dsWKFUZ75syZLr2up+EMOQAAAGAjJuQAAACAjViyYpG9e/dq9ciRI422eQu04cOHl1k7bqm4dOlSrc98WXV4hpdfflmr/fz8tNpxWYqnLlHx99d/PzdvVQbrREREVPixHTp0MNrmnCUkJGh148aNtTowMNBom7cqNH/9zVuTpaWlGe2CggKtr2ZN/UfJ9u3bSxw7vJd5GUJZ23Vu3rxZq83bfubm5lo2LriH4/cKEZEGDRqUebzjZeojIyO1vjvvvFOr+/fvr9Xt2rUz2nXq1NH6zEtjzPV7771ntM1Lib0NZ8gBAAAAGzEhBwAAAGzEhBwAAACwEWvI3SQlJcVo79mzR+szrzfu3bu3Vj///PNGu2nTplrfc889p9W//fZbpcaJiunXr59Wmy8VbV7n9sknn7h7SJVmXjPu+G/YsWNHFY/Gu5nXX5vz8Prrrxvtxx57zKXndtxizryG/Ny5c1p96tQprd65c6fRXrRokdZn3n7V/FmHrKwso33o0CGtLyQkRKt3795d4tjhPZo1a6bVH3/8sdOP/eWXX7TaMTvwDoWFhVqdnZ2t1Q0bNtTqffv2GW1Xt2s+fPiw0c7Ly9P6GjVqpNXHjh3T6k8//dSl1/JknCEHAAAAbMSEHAAAALARE3IAAADARqwhrwLp6elaPWTIEK2+8cYbtdpx3/J7771X62vVqpVWX3vttVYMES4yr5k179l69OhRrf7www/dPqbyBAUFafX06dPLPH79+vVGe8qUKe4Yks8yX2b6119/1epu3bpV+LkPHDhgtFetWqX17dq1S6u3bNlS4dcxGz16tNE2rx81rxmG95s8ebJWu3JdgrL2KId3yMnJ0WrzPvRr1qzRasdrK5ivy7J69WqtXrJkiVYfP37caC9btkzrM68hN/f7Es6QAwAAADZiQg4AAADYiAk5AAAAYCPWkNvAvDbr3Xff1eq33nrLaNesqX+JevToodW9evXS6o0bN1Z6fKi8goICrT5y5Igt43BcN/7EE09ofQ8//LBWm/eWnjVrltE+ceKEG0ZXfcyYMcPuIVSa+XoJjlzZoxqeyXwtheuuu87px5rXCGdkZFgxJHiQtLQ0rTZ/jqQyHOc1PXv21PrMn13w5c+rcIYcAAAAsBETcgAAAMBGLFmpAo6XuhYRGTx4sFZ37txZq83LVBw5XvpaROSrr76q5OjgDp988oktr2v+s7PjspShQ4dqfeY/Mw8aNMht44JvS0lJsXsIqKQvv/xSq+vVq1fm8Y5bao4cOdIdQ0I14biNsHmJilJKq9n2EAAAAIBbMCEHAAAAbMSEHAAAALARa8gtcumll2r12LFjjfbNN9+s9UVHRzv9vOfPn9dq8/Z5rlzOGNbx8/MrszZfZnj8+PFuGcfEiRO1+sknn9TqsLAwo/3+++9rfSNGjHDLmAB4n/r162t1eT9bXnvtNaPNtqiojC+++MLuIXgEl86QJycnS+fOnSU0NFQiIyNlwIABxfYbPXPmjCQlJUn9+vWlTp06MmjQIMnKyrJ00PB+ZAlWIUuwClmCVcgSXOXShHzTpk2SlJQkW7ZskbVr18rZs2fluuuuk5MnTxrHTJw4UT799FNZvny5bNq0SQ4fPlzsDDFAlmAVsgSrkCVYhSzBVS4tWfn888+1esmSJRIZGSnbt2+XHj16SG5urrz99tvywQcfyDXXXCMiIosXL5Y2bdrIli1bpGvXrtaNHF6NLMEqZAlWIUuwClmCqyq1hjw3N1dERCIiIkREZPv27XL27FlJSEgwjmndurXExsZKamqqVwfMvO771ltv1WrHNeMiIs2aNavwa23bts1oP/fcc1qfXftbu5u3Zcm8N6q5Nudlzpw5RnvRokVa3++//67V5n/b8OHDjXaHDh20vsaNG2v1gQMHtNpxbZ7jmk9f5m1Z8kbmz0xccsklWu24R7U38/UsLV682Gj7+7u2x8O3335r9XB8mq9nqTISExPtHoJHqPCEvKioSCZMmCBXXnmltGvXTkREMjMzJTAwUMLDw7Vjo6KiJDMzs8TnKSgokIKCAqPOy8ur6JDgpcgSrEKWYBWyBKuQJTijwtseJiUlSXp6eqWvmpScnCxhYWHGrUmTJpV6PngfsgSrkCVYhSzBKmQJzqjQhHzs2LGyZs0a2bBhg/Yn8+joaCksLJScnBzt+KysrFK3+psyZYrk5uYat4MHD1ZkSPBSZAlWIUuwClmCVcgSnOXSkhWllIwbN05SUlJk48aN0rx5c62/Y8eOEhAQIOvWrZNBgwaJiEhGRoYcOHBA4uPjS3zOoKAgCQoKquDwrRUVFaXVbdu2Ndrz5s3T+lq3bl3h10lLS9PqF198UatXr15ttH11n3Ffz1KNGjW0esyYMUb7wr/nAvOfHVu1auX065jXcW7YsEGrp06d6vRzeStfz5InMn9mwtX1x57K17N0+eWXa7Xj+mXzz5rCwkKtnj9/vlazPV/ZfD1LVmrRooXdQ/AILk3Ik5KS5IMPPpDVq1dLaGiosc4pLCxMQkJCJCwsTEaNGiUPPvigRERESN26dWXcuHESHx9frT6ggPKRJViFLMEqZAlWIUtwlUsT8gULFoiISK9evbT7Fy9eLCNHjhQRkVdeeUX8/f1l0KBBUlBQIImJidVmdwc4jyzBKmQJViFLsApZgqv8lPlvjzbLy8vTLvdtpQvbDV2wcOFCrTb/Oa8yf0ZxXEowa9Ysrc98mdjTp09X+HXslJubK3Xr1rV7GKVyZ5bM2w0uX75cqzt37lzqY81bxpX3X9BxW0Tzh4LGjx9f5mO9RXXOkrf48MMPjfYtt9yi9b355ptafe+991bJmEpClkpnnhyuXbvWaJuXHe3bt0+rW7Zs6bZxeSqyVDUu7DwjIvLf//5X6zMvpTKvr8/OznbfwCzkTJZ8Y+EfAAAA4KWYkAMAAAA2YkIOAAAA2KjCV+r0VHFxcVr98MMPG+0uXbpofRdddFGFX+fUqVNa7XhpdBGR559/3mifPHmywq8Dz3To0CGtvvnmm7XavIb2iSeecPq5X331Va2+8OEgEZGff/7Z6ecB3MX8OQgAqKj09HSjvWfPHq3P/Fm+iy++WKu9ZQ25MzhDDgAAANiICTkAAABgIybkAAAAgI18bg35wIEDy6zLsnPnTq1es2aN0T537pzWZ95bPCcnx+nXge85cuSIVk+fPr3MGvA2//znP422eR9yeIfdu3drteP1Mrp3717VwwGKcfz8nYjIW2+9pdXPPfecVo8bN85om+dw3oYz5AAAAICNmJADAAAANmJCDgAAANjITyml7B6Eo7y8PAkLC7N7GHBCbm6u1K1b1+5hlIoseQ+yBKuQJViFLFU98/v90UcfaXVCQoJWr1y50mjfeeedWp8nXQPGmSxxhhwAAACwERNyAAAAwEY+t+0hAAAAvE9eXp5WDxkyRKvN2x7ef//9Rtu8vbC3bYPIGXIAAADARkzIAQAAABsxIQcAAABsxBpyAAAAeBzzmvJx48aVWXszzpADAAAANmJCDgAAANjI4ybkHnbhUJTB079Wnj4+/MnTv1aePj78ydO/Vp4+PvzJ079Wnj4+/MmZr5XHTcjz8/PtHgKc5OlfK08fH/7k6V8rTx8f/uTpXytPHx/+5OlfK08fH/7kzNfKT3nYr1hFRUVy+PBhUUpJbGysHDx4UOrWrWv3sDxaXl6eNGnSpMreK6WU5OfnS0xMjPj7e9zvdAay5DqyVDKy5DqyVDKy5DqyVDKy5DpPzpLH7bLi7+8vjRs3Nj5ZW7duXQLmpKp8r8LCwqrkdSqDLFUcWdKRpYojSzqyVHFkSUeWKs4Ts+S5v/oBAAAA1QATcgAAAMBGHjshDwoKkmnTpklQUJDdQ/F4vFdl4/1xHu9V2Xh/nMd7VTbeH+fxXpWN98d5nvxeedyHOgEAAIDqxGPPkAMAAADVARNyAAAAwEZMyAEAAAAbMSEHAAAAbOSxE/L58+dLs2bNJDg4WOLi4mTr1q12D8lWycnJ0rlzZwkNDZXIyEgZMGCAZGRkaMecOXNGkpKSpH79+lKnTh0ZNGiQZGVl2TRiz0GWdGSp4siSjixVHFnSkaWKI0s6r82S8kDLli1TgYGBatGiRerHH39U99xzjwoPD1dZWVl2D802iYmJavHixSo9PV3t2LFD9e3bV8XGxqoTJ04Yx9x3332qSZMmat26dWrbtm2qa9euqlu3bjaO2n5kqTiyVDFkqTiyVDFkqTiyVDFkqThvzZJHTsi7dOmikpKSjPr8+fMqJiZGJScn2zgqz3L06FElImrTpk1KKaVycnJUQECAWr58uXHMrl27lIio1NRUu4ZpO7JUPrLkHLJUPrLkHLJUPrLkHLJUPm/JksctWSksLJTt27dLQkKCcZ+/v78kJCRIamqqjSPzLLm5uSIiEhERISIi27dvl7Nnz2rvW+vWrSU2Nrbavm9kyTlkqXxkyTlkqXxkyTlkqXxkyTnekiWPm5AfO3ZMzp8/L1FRUdr9UVFRkpmZadOoPEtRUZFMmDBBrrzySmnXrp2IiGRmZkpgYKCEh4drx1bn940slY8sOYcslY8sOYcslY8sOYcslc+bslTTtldGhSUlJUl6erps3rzZ7qHAy5ElWIUswSpkCVbxpix53BnyBg0aSI0aNYp92jUrK0uio6NtGpXnGDt2rKxZs0Y2bNggjRs3Nu6Pjo6WwsJCycnJ0Y6vzu8bWSobWXIeWSobWXIeWSobWXIeWSqbt2XJ4ybkgYGB0rFjR1m3bp1xX1FRkaxbt07i4+NtHJm9lFIyduxYSUlJkfXr10vz5s21/o4dO0pAQID2vmVkZMiBAweq7ftGlkpGllxHlkpGllxHlkpGllxHlkrmtVmy7eOkZVi2bJkKCgpSS5YsUTt37lSjR49W4eHhKjMz0+6h2eb+++9XYWFhauPGjerIkSPG7dSpU8Yx9913n4qNjVXr169X27ZtU/Hx8So+Pt7GUduPLBVHliqGLBVHliqGLBVHliqGLBXnrVnyyAm5UkrNnTtXxcbGqsDAQNWlSxe1ZcsWu4dkKxEp8bZ48WLjmNOnT6sxY8aoevXqqVq1aqmBAweqI0eO2DdoD0GWdGSp4siSjixVHFnSkaWKI0s6b82Sn1JKVcWZeAAAAADFedwacgAAAKA6YUIOAAAA2IgJOQAAAGAjJuQAAACAjZiQAwAAADZiQg4AAADYiAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANiICTkAAABgIybkAAAAgI2YkAMAAAA2YkIOAAAA2IgJOQAAAGAjJuQAAACAjZiQAwAAADZiQg4AAADYiAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANiICTkAAABgIybkAAAAgI2YkAMAAAA2YkIOAAAA2IgJOQAAAGAjJuQAAACAjZiQAwAAADZiQg4AAADYiAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANiICTkAAABgIybkAAAAgI2YkAMAAAA2YkIOAAAA2IgJOQAAAGAjJuQAAACAjZiQAwAAADZiQg4AAADYiAk5AAAAYCMm5C7av3+/+Pn5yUsvvWTZc27cuFH8/Pxk48aNlj0nPB9ZAuBp+L4EK5En51WLCfmSJUvEz89Ptm3bZvdQ3GLlypUydOhQadGihdSqVUsuvfRSeeihhyQnJ8fuofkcX89SRkaGTJw4Ubp16ybBwcHi5+cn+/fvt3tYKAc/9Ko3vi/BSr6eJ7Nrr71W/Pz8ZOzYsbaOo1pMyH3d6NGjZdeuXXL77bfLnDlz5Prrr5d58+ZJfHy8nD592u7hwYukpqbKnDlzJD8/X9q0aWP3cHyar//QS0lJkcTERImJiZGgoCBp3LixDB48WNLT0+0eGrwM35fgLitXrpTU1FS7hyEiIjXtHgAqb8WKFdKrVy/tvo4dO8odd9wh77//vtx99932DAxep3///pKTkyOhoaHy0ksvyY4dO+weErzUf//7X6lXr56MHz9eGjRoIJmZmbJo0SLp0qWLpKamSocOHeweIrwE35fgDmfOnJGHHnpIJk+eLFOnTrV7OJwhv6CwsFCmTp0qHTt2lLCwMKldu7ZcddVVsmHDhlIf88orr0jTpk0lJCREevbsWeKZn927d8vgwYMlIiJCgoODpVOnTvLJJ5+UO55Tp07J7t275dixY+Uea56Mi4gMHDhQRER27dpV7uNhLW/OUkREhISGhpZ7HFCeqVOnyrJly2Ty5MkyatQoefzxx+Xbb7+Vs2fPyoIFC+weXrXD9yVYyZvzdMHMmTOlqKhIJk2a5PRj3IkJ+f/Ly8uTt956S3r16iUzZsyQ6dOnS3Z2tiQmJpb42/jSpUtlzpw5kpSUJFOmTJH09HS55pprJCsryzjmxx9/lK5du8quXbvk0UcflVmzZknt2rVlwIABkpKSUuZ4tm7dKm3atJF58+ZV6N+TmZkpIiINGjSo0ONRcb6WJdjHF37oOYqMjJRatWrx+RYb8H0JVvL2PB04cEBeeOEFmTFjhoSEhLj0b3cbVQ0sXrxYiYj67rvvSj3m3LlzqqCgQLvvjz/+UFFRUequu+4y7tu3b58SERUSEqIOHTpk3J+WlqZERE2cONG4r3fv3qp9+/bqzJkzxn1FRUWqW7duqlWrVsZ9GzZsUCKiNmzYUOy+adOmVeSfrEaNGqVq1Kihfvrppwo9HiWrTll68cUXlYioffv2ufQ4OMeZLGVnZ6tGjRqpBx98UC1YsEDNnDlTXXrppSogIED9+9//No67kKX27durZs2aqRkzZqinnnpKRUREqIYNG6rMzEzj2PT0dBUWFqbatm2rZsyYoebNm6d69Oih/Pz81MqVK43jrMrSH3/8oY4ePar+85//qLvuukuJiHrjjTecfjzKx/clWKk65Gnw4MGqW7duRi0iKikpyanHugtryP9fjRo1pEaNGiIiUlRUJDk5OVJUVCSdOnWS77//vtjxAwYMkIsuusiou3TpInFxcfLZZ5/Jyy+/LMePH5f169fL008/Lfn5+ZKfn28cm5iYKNOmTZPffvtNew5HvXr1kv9lxHUffPCBvP322/LII49Iq1atKvQcqDhfyhLsVa9ePdm/f78EBgYa991zzz3SunVrmTt3rrz99tva8T///LPs2bPHyML1118vcXFxMmPGDHn55ZdFRGT8+PESGxsr3333nQQFBYmIyJgxY6R79+4yefJkY7mbVbp27SoZGRkiIlKnTh154oknZNSoUZa+BsrH9yVYyZvztGHDBvn4448lLS3NlX+y27FkxcE777wjl112mQQHB0v9+vWlYcOG8o9//ENyc3OLHVvSRPeSSy4xtmL6+eefRSklTz75pDRs2FC7TZs2TUREjh49avm/4euvv5ZRo0ZJYmKiPPfcc5Y/P5zjC1mC/WrUqGFMxouKiuT48eNy7ty5Cv3QExHjh96QIUMkPz9fjh07JseOHZPff/9dEhMTZc+ePfLbb7+VOp4LP/SmT5/u9L9h8eLF8vnnn8trr70mbdq0kdOnT8v58+edfjysw/clWMkb83Tu3Dl54IEHZPjw4dK5c+dKP5+VOEP+/9577z0ZOXKkDBgwQB5++GGJjIyUGjVqSHJysuzdu9fl5ysqKhIRkUmTJkliYmKJx7Rs2bJSYzb74YcfpH///tKuXTtZsWKF1KzJl9cOvpAleI533nlHZs2aJbt375azZ88a9zdv3rzYsaX90Pvoo49ERP+h9+STT5b4ekePHi31LFRFxMfHG+1hw4YZ29ZZuWc6ysf3JVjJW/O0dOlSycjIkIULFxbbyz4/P1/2799vfNalqjFj+38rVqyQFi1ayMqVK8XPz8+4/8JvZmZ79uwpdt9PP/0kzZo1ExGRFi1aiIhIQECAJCQkWD9gk71798r1118vkZGR8tlnn0mdOnXc/poombdnCZ7DW3/olaZevXpyzTXXyPvvv8+EvIrxfQlW8tY8HThwQM6ePStXXnllsb6lS5fK0qVLJSUlRQYMGOC2MZSGJSv/78JaKMc1SGlpaaVuGL9q1SrtT7tbt26VtLQ06dOnj4j8bzeBXr16ycKFC+XIkSPFHp+dnV3meFzZzSAzM1Ouu+468ff3ly+++EIaNmxY7mPgPt6cJXgWxx96w4cPl8TERElISJAzZ86UeLyrP/RKurl7e7nTp0+X+CdtuBffl2Alb83TsGHDJCUlpdhNRKRv376SkpIicXFxZT6Hu1SrM+SLFi2Szz//vNj948ePl379+snKlStl4MCBcsMNN8i+ffvk9ddfl7Zt28qJEyeKPaZly5bSvXt3uf/++6WgoEBmz54t9evXl0ceecQ4Zv78+dK9e3dp37693HPPPdKiRQvJysqS1NRUOXTokPzwww+ljnXr1q1y9dVXy7Rp08pdr3n99dfLL7/8Io888ohs3rxZNm/ebPRFRUXJtdde68S7A1f4apZyc3Nl7ty5IiLyzTffiIjIvHnzJDw8XMLDw22/tHB14/hD78JZqAs/9GJjY4sdf+GH3oUlJxd+6E2YMEFE9B9648aNk0aNGmmPz87OLvMX+lOnTsmBAwekQYMG5W6pevToUYmMjNTu279/v6xbt046depU9j8cFcL3JVjJF/PUunVrad26dYl9zZs3t+XM+AXVakJe2sUoRo4cKSNHjpTMzExZuHChfPHFF9K2bVt57733ZPny5bJx48ZijxkxYoT4+/vL7Nmz5ejRo9KlSxeZN2+e9gOubdu2sm3bNnnqqadkyZIl8vvvv0tkZKRcccUVll4V6kJIZ86cWayvZ8+eTMjdwFez9McffxRbWzxr1iwREWnatCk/+NzAF3/oiYi0b99eevfuLZdffrnUq1dP9uzZI2+//bacPXtWXnjhBeffIDiN70uwkq/myWPZsNUiAFR7F/b6Le128OBBVVRUpJ5//nnVtGlTFRQUpK644gq1Zs0adccdd6imTZsaz3Vhr98XX3xRzZo1SzVp0kQFBQWpq666Sv3www/FXnvv3r1qxIgRKjo6WgUEBKiLLrpI9evXT61YscI4prJ7/U6bNk116tRJ1atXT9WsWVPFxMSoYcOGqf/85z+VedsAwCf5KcVGoAAAAIBd+FAnAAAAYCMm5AAAAICNmJADAAAANmJCDgAAANjIbRPy+fPnS7NmzSQ4OFji4uJk69at7nop+DiyBKuQJViFLMEqZAkibpqQf/jhh/Lggw/KtGnT5Pvvv5cOHTpIYmKiHD161B0vBx9GlmAVsgSrkCVYhSzhArdsexgXFyedO3eWefPmiYhIUVGRNGnSRMaNGyePPvpomY8tKiqSw4cPS2hoqHFlOngWpZTk5+dLTEyM+Pu7d9UTWfJtZAlWIUuwClmCVVzJkuVX6iwsLJTt27fLlClTjPv8/f0lISFBUlNTix1fUFAgBQUFRv3bb79J27ZtrR4W3ODgwYPSuHFjtz0/Wao+yBKsQpZgFbIEqziTJct/9Tt27JicP39eoqKitPujoqIkMzOz2PHJyckSFhZm3AiX9wgNDXXr85Ol6oMswSpkCVYhS7CKM1myfZeVKVOmSG5urnE7ePCg3UOCkzztT2RkyXuRJViFLMEqZAlWcSZLli9ZadCggdSoUUOysrK0+7OysiQ6OrrY8UFBQRIUFGT1MOADyBKsQpZgFbIEq5AlOLL8DHlgYKB07NhR1q1bZ9xXVFQk69atk/j4eKtfDj6MLMEqZAlWIUuwClmCRrnBsmXLVFBQkFqyZInauXOnGj16tAoPD1eZmZnlPjY3N1eJCDcvuOXm5rojPmSpGt7IEjeyxM3TbmSJW1VmyS0TcqWUmjt3roqNjVWBgYGqS5cuasuWLU49joB5z60qvlkpRZaqw40scSNL3DztRpa4VWWW3LIPeWXk5eVJWFiY3cOAE3Jzc6Vu3bp2D6NUZMl7kCVYhSzBKmQJVnEmS7bvsgIAAABUZ0zIAQAAABsxIQcAAABsxIQcAAAAsBETcgAAAMBGTMgBAAAAG9W0ewAAdK+++qpWP/DAA0Y7PT1d6+vXr59W//rrr+4bGAAAPsjxaqkiIn5+flp9zTXXuH0MnCEHAAAAbMSEHAAAALARE3IAAADARqwht0FoaKhW16lTR6tvuOEGo92wYUOt7+WXX9bqgoICi0eHqtasWTOtvv3227W6qKjIaLdp00bra926tVazhrx6u+SSS7Q6ICBAq3v06GG0X3vtNa3PMWeVtXr1aq0eNmyY0S4sLLTsdVB1zFnq1q2b0X7++ee1viuvvLJKxgRUxiuvvGK0HfMsIrJ06dKqHg5nyAEAAAA7MSEHAAAAbMSSFTdxXIYwefJkrS8+Pl6r27Vr5/TzNmrUSKsdt8SDd8rOztbqr776Sqv79+9flcOBh/vLX/5itEeOHKn13XLLLVrt76+fc4mJiTHa5iUqSimLRlg8s6+//rrRnjBhgtaXl5dn2evCfcLCwrR6w4YNRjszM1Pri46O1mpzP2CHF154Qavvu+8+o3327Fmtz7wNYlXgDDkAAABgIybkAAAAgI2YkAMAAAA2Yg15BZm3mzOvi7ztttuMdkhIiNZnviTrwYMHtTo/P99om7e5GzJkiFabty7bvXt3GaOGJzp58qRWs3UhypKcnGy0+/bta+NInDdixAij/fbbb2t933zzTVUPBxYzrxlnDTk8UdeuXbXacSvPzZs3a30fffRRlYzJEWfIAQAAABsxIQcAAABsxIQcAAAAsBFryMvguO/qjBkztL6hQ4dqdWhoqNPPu2fPHq1OTEzUasd1TeY14Q0aNCizhvcJDw/X6g4dOtgzEHiFtWvXGu3y1pAfPXpUqx3Xb5v3KDfvS27meGnpnj17ljtOVB/mz0UBZenRo4dWP/7440b71ltv1fqOHz9e4dcxP5f5mi979+412pMmTarw61iFM+QAAACAjZiQAwAAADZiQg4AAADYiDXkZRg4cKDRvvvuuyv8PI7rlERErr32Wq0270PesmXLCr8WvE+tWrW0OjY21unHdu7cWavNnzlgT3Pfs2DBAqO9atWqMo89e/asVldmP+i6desa7fT0dK0vJiamzMc6jnPbtm0VHgM8k1JKq4ODg20aCbzBG2+8odWtWrUy2m3bttX6zPuDu+Kxxx7T6vr162v1PffcY7R/+OGHCr+OVThDDgAAANjI5Qn5V199JTfeeKPExMSIn59fsTM0SimZOnWqNGrUSEJCQiQhIaHYriKACFmCdcgSrEKWYBWyBFe4vGTl5MmT0qFDB7nrrrvk5ptvLtY/c+ZMmTNnjrzzzjvSvHlzefLJJyUxMVF27tzpdX/GuuWWW5w+dv/+/Vr93XffGe3JkydrfeYlKmZt2rRx+nW9WXXKUlkOHz6s1UuWLNHq6dOnl/pYc19OTo5Wz5s3rxIj8x7VKUvnzp0z2uV9L7GS4/as9erVc+mxhw4dMtoFBQWWjckdqlOW3KVTp05avWXLFptGYi+yVLJTp05pteOSp8r8uy+//HKtbtq0qVabt3b1tPfY5Ql5nz59pE+fPiX2KaVk9uzZ8sQTT8hNN90kIiJLly6VqKgoWbVqlQwbNqxyo4VPIUuwClmCVcgSrEKW4ApL15Dv27dPMjMzJSEhwbgvLCxM4uLiJDU1tcTHFBQUSF5ennYDyBKsQpZgFbIEq5AlmFk6Ib/wCf6oqCjt/qioqFI/3Z+cnCxhYWHGrUmTJlYOCV6KLMEqZAlWIUuwClmCme3bHk6ZMkUefPBBo87Ly/OYkDluiTN69Git78svv9Tqn3/+WavNl6x2hfk/KJzjyVlyxTPPPKPVZa0hh3v4SpYqw/wnc8fvhyEhIS4919SpUy0ZkzfylSw5fnZBRCQ3N9doh4WFaX0XX3xxlYypuvHWLJl/prVv316rd+3aZbRd3X6wdu3aRtv8eT3zlsLmzzKsWLHCpddyN0vPkEdHR4uISFZWlnZ/VlaW0WcWFBQkdevW1W4AWYJVyBKsQpZgFbIEM0sn5M2bN5fo6GhZt26dcV9eXp6kpaVJfHy8lS8FH0eWYBWyBKuQJViFLMHM5SUrJ06c0JZn7Nu3T3bs2CERERESGxsrEyZMkGeffVZatWplbOMTExMjAwYMsHLc8AFkCVYhS7AKWYJVyBJc4fKEfNu2bXL11Vcb9YX1THfccYcsWbJEHnnkETl58qSMHj1acnJypHv37vL555973H6PznDcH7oq1/FWl9+Oq1OWKsPf/88/ZJn3UcX/kCXX3XbbbVr96KOPanXLli21OiAgwOnn3rFjh1afPXvWtcHZiCyVzHyNg6+//tpo9+vXr4pH4x2qa5bM69odP38iUvzzCGPHjjXa2dnZLr3Wyy+/bLTN144xX+PjyiuvdOm5q5rLE/JevXppm7ib+fn5ydNPPy1PP/10pQYG30eWYBWyBKuQJViFLMEVlq4hBwAAAOAaJuQAAACAjWzfh9xXPfDAA0bbcZ9MZ5j36HT07bffanVpV/SC73BcN17Wnz9RPTRr1sxoDx8+XOtzvOpfebp3767VrmTLfIVA8/rzzz77TKtPnz7t9HMD8D7t2rUz2ikpKVpfgwYNtHru3LlavWnTJqdfZ9KkSVo9cuTIUo997rnnnH5eT8AZcgAAAMBGTMgBAAAAG7FkxUnmS7C2bdtWq6dNm6bVffv2LfW5HLexEyl7Kzvztj133nmnVp8/f77UxwLwfo5/ChYR+eSTT4x2bGxsVQ9HRPQt70RE3njjDVvGAc9Uv359u4cAi9WsqU8Xb7/9dq1+++23jXZ5cxzz1s5Tpkwx2o7bGIqIREREaLV5a0M/Pz+jvXTpUq1v4cKF4k04Qw4AAADYiAk5AAAAYCMm5AAAAICNWEPuwHxp6CuuuMJof/zxx1pfo0aNtNq8rZfj2m/z1oTXX3+9VpvXpzsyr9u6+eabtfrVV1/V6sLCwlKfC4D3c1wz6dh2lSufZTEzXyq9T58+Wv3Pf/6zwuOC9+vfv7/dQ4DFhg0bptVvvfWWVjtum2r+XvLzzz9rdadOnUqtb7rpJq3voosu0mrz3Cs7O9to33XXXSWO3VtwhhwAAACwERNyAAAAwEZMyAEAAAAbVes15IGBgVptXtu9cuXKUh/71FNPafX69eu1+ptvvjHa5n00zcea9xl21LBhQ61OTk7W6gMHDmj1qlWrjHZBQUGpzwvv4bjWt7x1vj169NDqefPmuWVMqDrp6ela3atXL6Nt3gv4iy++0OozZ85U+HVHjRql1ePGjavwc8H3bNiwwWibP1MA7zd06FCtXrx4sVafPXtWq3Nycoz23/72N63vjz/+0OpZs2Zpdc+ePY22eX25+XMyjmvVRUQaNGhgtA8ePKj1OX6vFBHZu3eveDLOkAMAAAA2YkIOAAAA2IgJOQAAAGCjarWG3LzPuHkd+MMPP1zqY8376s6dO1erHddPiehrvz/77DOtr3379lpt3jt85syZRtu8vty8R+f777+v1f/617+M9owZM7Q+8zousx07dpTZD3s4rhs3r58zM+9T37ZtW6O9c+dOawcGW/z6669G+7nnnnPb60yfPl2rWUMOR+bPLzky/6xt2rSpVjtmGJ7p3nvv1Wrz1/vZZ5/VavMa87KYv5csXLjQaMfHxzv9PCL6GnPHzzWIeP6acTPOkAMAAAA2YkIOAAAA2Mjnl6zUqFHDaD/zzDNa36RJk7T65MmTWv3oo48a7WXLlml95iUq5q16HLebu+KKK7S+PXv2aPX999+v1Y5/dqlbt67W161bN62+7bbbtNrxksVr166Vspi3CGrevHmZx8Mer7/+utE2/xmxPKNHjzbaEyZMsGpIqAYSExPtHgI82Llz50rtM29VFxQU5O7hwGKrV6/WavM20Ob5gysctyoUKXvr51tvvVWrzdvAOjp06FCFx+QJOEMOAAAA2IgJOQAAAGAjJuQAAACAjXx+DbnjGlrzmvFTp05ptXl97pdffmm0u3btqvXdeeedWt2nTx+tDgkJMdpPP/201mfeHqistVh5eXla/fnnn5dZO663Ml++1mzixIll9sMz7N692+4hwI3MW8Rdd911Wr1+/XqtPn36tFvGYf6e9uqrr7rldeAbHNcYm79HtW7dWqvNn18ZM2aM28YFa1j5/z8sLEyrb7nlFq12/KyceavCjz76yLJxeDrOkAMAAAA2cmlCnpycLJ07d5bQ0FCJjIyUAQMGSEZGhnbMmTNnJCkpSerXry916tSRQYMGSVZWlqWDhvcjS7AKWYJVyBKsQpbgKpcm5Js2bZKkpCTZsmWLrF27Vs6ePSvXXXedtl3gxIkT5dNPP5Xly5fLpk2b5PDhw8WuHgiQJViFLMEqZAlWIUtwlZ8q71rcZcjOzpbIyEjZtGmT9OjRQ3Jzc6Vhw4bywQcfyODBg0Xkf2vL2rRpI6mpqcXWYZckLy+v2Hqjyjhy5IjRdrycvYhIQUGBVpvXwdWuXdtot2zZ0qXXdbzsdHJystZ3/vx5l57LU+Xm5hbbJ72ivCFLnuCnn37S6osvvrjM4/39//yd25xhT7qscHXLUvfu3Y32448/rvVde+21Wm2+PkBl9v+NiIgw2n379tX65s6dq9WhoaGlPo95Hbvj9Q9Eil/CuipVtyx5gtmzZ2u1+fMIUVFRWn3mzBl3D8kSZMkaU6ZM0WrzNWGys7ONdufOnbU+b99b/AJnslSpNeS5ubki8uc3+e3bt8vZs2clISHBOKZ169YSGxsrqampJT5HQUGB5OXlaTdUP2QJViFLsApZglXIEspT4Ql5UVGRTJgwQa688krjKkuZmZkSGBgo4eHh2rFRUVGSmZlZ4vMkJydLWFiYcWvSpElFhwQvRZZgFbIEq5AlWIUswRkVnpAnJSVJenp6sUvKu2rKlCmSm5tr3Crz51h4J7IEq5AlWIUswSpkCc6o0D7kY8eOlTVr1shXX30ljRs3Nu6Pjo6WwsJCycnJ0X7ry8rKkujo6BKfKygoSIKCgioyDKc4/qZpXkNuft0OHTqU+jyfffaZVn/11VdavWrVKq3ev3+/0faVNePu4E1Z8gQ//vijVrdo0aLM44uKitw5HI/iTVmaN2+e0b5wxqw0jzzyiFbn5+dX+HUd16f/9a9/1frK+zjRxo0bjfaCBQu0PjvXjLuDN2XJE5mzVFhYaNNI7Fcds9S0aVOtvvvuu7XanI833njDaPvKmvGKcOkMuVJKxo4dKykpKbJ+/fpiHzbq2LGjBAQEyLp164z7MjIy5MCBAxIfH2/NiOETyBKsQpZgFbIEq5AluMqlM+RJSUnywQcfyOrVqyU0NNQ4+xwWFiYhISESFhYmo0aNkgcffFAiIiKkbt26Mm7cOImPj3fqE8OoPsgSrEKWYBWyBKuQJbjKpW0P/fz8Srx/8eLFMnLkSBH533ZGDz30kPz973+XgoICSUxMlNdee63UP8GYWb2Nj+PWXQMGDND6zH+yPXr0qFYvWrTIaP/xxx9aX3X+E9wFldkSyhuz5An69Omj1Z9++mmZxzu+z5dcconW5yvbHnpjlnbs2GG0y1uy4i7m9818QRJztsaPH2+0PXnbuuqWJU9g3vbwgQce0OpBgwZpdUpKiruHZAmyVDHm7XnNSyvfe+89rb7wfvgyZ7Lk0hlyZ+buwcHBMn/+fJk/f74rT41qhizBKmQJViFLsApZgqsqtQ85AAAAgMphQg4AAADYqELbHnoTxy3C3n33Xa3PXAOebufOnVq9a9curW7Tpk1VDgcV5Lhmcty4cVrfHXfcYdnrmD8ncOrUKaP99ddfa32OW4+JiKSnp1s2Dvi2IUOGaHVBQYFWm79PwbctXrxYq5955hmtXr16dVUOx2twhhwAAACwERNyAAAAwEZMyAEAAAAbubQPeVXw1H01UVxl9mitCmTJe1TnLJkvhW3ek/fZZ5/V6nr16hntVatWaX1r167VavNazQsXJ/Fl1TlLdlm2bJlWmz/L0r9/f63+9ddf3T4mK5AlWMWZLHGGHAAAALARE3IAAADARkzIAQAAABuxhhwVxvo6WIUswSpkCVYhS7AKa8gBAAAAD8eEHAAAALARE3IAAADARkzIAQAAABsxIQcAAABsxIQcAAAAsBETcgAAAMBGTMgBAAAAGzEhBwAAAGzkcRNyD7twKMrg6V8rTx8f/uTpXytPHx/+5OlfK08fH/7k6V8rTx8f/uTM18rjJuT5+fl2DwFO8vSvlaePD3/y9K+Vp48Pf/L0r5Wnjw9/8vSvlaePD39y5mvlpzzsV6yioiI5fPiwKKUkNjZWDh48KHXr1rV7WB4tLy9PmjRpUmXvlVJK8vPzJSYmRvz9Pe53OgNZch1ZKhlZch1ZKhlZch1ZKhlZcp0nZ6mm20fjIn9/f2ncuLHk5eWJiEjdunUJmJOq8r0KCwurktepDLJUcWRJR5YqjizpyFLFkSUdWao4T8yS5/7qBwAAAFQDTMgBAAAAG3nshDwoKEimTZsmQUFBdg/F4/FelY33x3m8V2Xj/XEe71XZeH+cx3tVNt4f53nye+VxH+oEAAAAqhOPPUMOAAAAVAdMyAEAAAAbMSEHAAAAbMSEHAAAALCRx07I58+fL82aNZPg4GCJi4uTrVu32j0kWyUnJ0vnzp0lNDRUIiMjZcCAAZKRkaEdc+bMGUlKSpL69etLnTp1ZNCgQZKVlWXTiD0HWdKRpYojSzqyVHFkSUeWKo4s6bw2S8oDLVu2TAUGBqpFixapH3/8Ud1zzz0qPDxcZWVl2T002yQmJqrFixer9PR0tWPHDtW3b18VGxurTpw4YRxz3333qSZNmqh169apbdu2qa5du6pu3brZOGr7kaXiyFLFkKXiyFLFkKXiyFLFkKXivDVLHjkh79Kli0pKSjLq8+fPq5iYGJWcnGzjqDzL0aNHlYioTZs2KaWUysnJUQEBAWr58uXGMbt27VIiolJTU+0apu3IUvnIknPIUvnIknPIUvnIknPIUvm8JUset2SlsLBQtm/fLgkJCcZ9/v7+kpCQIKmpqTaOzLPk5uaKiEhERISIiGzfvl3Onj2rvW+tW7eW2NjYavu+kSXnkKXykSXnkKXykSXnkKXykSXneEuWPG5CfuzYMTl//rxERUVp90dFRUlmZqZNo/IsRUVFMmHCBLnyyiulXbt2IiKSmZkpgYGBEh4erh1bnd83slQ+suQcslQ+suQcslQ+suQcslQ+b8pSTdteGRWWlJQk6enpsnnzZruHAi9HlmAVsgSrkCVYxZuy5HFnyBs0aCA1atQo9mnXrKwsiY6OtmlUnmPs2LGyZs0a2bBhgzRu3Ni4Pzo6WgoLCyUnJ0c7vjq/b2SpbGTJeWSpbGTJeWSpbGTJeWSpbN6WJY+bkAcGBkrHjh1l3bp1xn1FRUWybt06iY+Pt3Fk9lJKydixYyUlJUXWr18vzZs31/o7duwoAQEB2vuWkZEhBw4cqLbvG1kqGVlyHVkqGVlyHVkqGVlyHVkqmddmybaPk5Zh2bJlKigoSC1ZskTt3LlTjR49WoWHh6vMzEy7h2ab+++/X4WFhamNGzeqI0eOGLdTp04Zx9x3330qNjZWrV+/Xm3btk3Fx8er+Ph4G0dtP7JUHFmqGLJUHFmqGLJUHFmqGLJUnLdmySMn5EopNXfuXBUbG6sCAwNVly5d1JYtW+wekq1EpMTb4sWLjWNOnz6txowZo+rVq6dq1aqlBg4cqI4cOWLfoD0EWdKRpYojSzqyVHFkSUeWKo4s6bw1S35KKVUVZ+IBAAAAFOdxa8gBAACA6oQJOQAAAGAjJuQAAACAjZiQAwAAADZiQg4AAADYiAk5AAAAYCMm5AAAAICNmJADAAAANmJCDgAAANiICTkAAABgIybkAAAAgI2YkAMAAAA2+j+wkFIviYen7QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__UjhTmBJBaY"
      },
      "source": [
        "**Pré-Processamento dos Dados**\n",
        "\n",
        " Primeiro trabalhamos com os dados dos atributos não alvo (*features*), checando o formato dos *datasets* nas variáveis *x_train e x_test*. emos que eles têm os formatos (60000, 28, 28) e (10000, 28, 28) respectivamente.\n",
        "\n",
        " O primeiro número indica a quantidade de imagens contidas em cada *dataset*: 60000 para o treino e 10000 para o teste. Os outros dois números são a quantidade de pixeis de cada imagem, 28 píxeis verticais e 28 píxeis horizontais.\n",
        "\n",
        "Sendo assim, cada imagem é representada como matrizes de números (28 x 28). Já que as imagens são monocromáticas, cada elemento da matriz significa a luminosidade doassociad àquela posição do *pixel*,em valores que vão de 0 a 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU2vN7wXJpMR",
        "outputId": "cd1b66cd-10a4-4bc4-ef9a-60c86efb0db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando matriz da imagem (28x28)\n",
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48xCoeFqc8X8",
        "outputId": "def25db1-d090-4db7-b035-352f5de04ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2-4DkEMOfzR"
      },
      "source": [
        "Para usar os *datasets* no treinamento e teste de modelos de aprendizado de máquina é necessario, inicialmente, pré-processar os dados.\n",
        "\n",
        "Primeiro fazemos o *reshape*, incluindo uma nova dimensão que indica que as imagens são monocromaticas (*reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)*).\n",
        "\n",
        "Depois normalizamos os dados dos atributos não alvo, dividindo os valores de luminosidade dos pixeis pelo maior valor possivel, *255*, com isso fazendo com que estes valores fiquem na faixa entre 0 e 1.\n",
        "\n",
        "Com essas duas ações encerramos  pré-processamento dos atributos não alvo (*features*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW1ZnGTP7BY3"
      },
      "outputs": [],
      "source": [
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar mudança feita na matriz da imagem (28x28)\n",
        "# Os valores mudaram da escala de 0 a 255 para a escala de 0 a 1\n",
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXBBU_kkdeJU",
        "outputId": "5546446e-d88a-4d73-aea2-ec4016483a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.01176471]\n",
            "  [0.07058824]\n",
            "  [0.07058824]\n",
            "  [0.07058824]\n",
            "  [0.49411765]\n",
            "  [0.53333333]\n",
            "  [0.68627451]\n",
            "  [0.10196078]\n",
            "  [0.65098039]\n",
            "  [1.        ]\n",
            "  [0.96862745]\n",
            "  [0.49803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.11764706]\n",
            "  [0.14117647]\n",
            "  [0.36862745]\n",
            "  [0.60392157]\n",
            "  [0.66666667]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.88235294]\n",
            "  [0.6745098 ]\n",
            "  [0.99215686]\n",
            "  [0.94901961]\n",
            "  [0.76470588]\n",
            "  [0.25098039]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.19215686]\n",
            "  [0.93333333]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.98431373]\n",
            "  [0.36470588]\n",
            "  [0.32156863]\n",
            "  [0.32156863]\n",
            "  [0.21960784]\n",
            "  [0.15294118]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.07058824]\n",
            "  [0.85882353]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.77647059]\n",
            "  [0.71372549]\n",
            "  [0.96862745]\n",
            "  [0.94509804]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.31372549]\n",
            "  [0.61176471]\n",
            "  [0.41960784]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.80392157]\n",
            "  [0.04313725]\n",
            "  [0.        ]\n",
            "  [0.16862745]\n",
            "  [0.60392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.05490196]\n",
            "  [0.00392157]\n",
            "  [0.60392157]\n",
            "  [0.99215686]\n",
            "  [0.35294118]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.54509804]\n",
            "  [0.99215686]\n",
            "  [0.74509804]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.04313725]\n",
            "  [0.74509804]\n",
            "  [0.99215686]\n",
            "  [0.2745098 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.1372549 ]\n",
            "  [0.94509804]\n",
            "  [0.88235294]\n",
            "  [0.62745098]\n",
            "  [0.42352941]\n",
            "  [0.00392157]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.31764706]\n",
            "  [0.94117647]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.46666667]\n",
            "  [0.09803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.17647059]\n",
            "  [0.72941176]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.58823529]\n",
            "  [0.10588235]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.0627451 ]\n",
            "  [0.36470588]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.73333333]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.97647059]\n",
            "  [0.99215686]\n",
            "  [0.97647059]\n",
            "  [0.25098039]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.18039216]\n",
            "  [0.50980392]\n",
            "  [0.71764706]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.81176471]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.15294118]\n",
            "  [0.58039216]\n",
            "  [0.89803922]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.98039216]\n",
            "  [0.71372549]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09411765]\n",
            "  [0.44705882]\n",
            "  [0.86666667]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.78823529]\n",
            "  [0.30588235]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09019608]\n",
            "  [0.25882353]\n",
            "  [0.83529412]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.77647059]\n",
            "  [0.31764706]\n",
            "  [0.00784314]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.07058824]\n",
            "  [0.67058824]\n",
            "  [0.85882353]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.76470588]\n",
            "  [0.31372549]\n",
            "  [0.03529412]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.21568627]\n",
            "  [0.6745098 ]\n",
            "  [0.88627451]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.95686275]\n",
            "  [0.52156863]\n",
            "  [0.04313725]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.53333333]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.83137255]\n",
            "  [0.52941176]\n",
            "  [0.51764706]\n",
            "  [0.0627451 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_Yh2zuQTTx"
      },
      "source": [
        "Para os atributos alvo (*target*) é necessário fazer o *one hot enconding* das classes. Esta operação consistem em transformar as classes adicionando novas colunas, que indicam a presença ou não da classe. Isto é, como neste *dataset* as classes são os números de 0 a 9, adicionamos 10 novas colunas, numeradas de 0 a 9. Para cada amostra, cada uma destas novas colunas terá os valores 0 ou 1, onde 0 indica   que a amostra não é daquela classe e 1 indica que a amostra é daquela classe.\n",
        "\n",
        "Printamos a primeira amostra do conjunto de treinamento , antes e depois da aplicação da operação, para vermos seu efeito sobre a amostra."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3buL4_3IfCsA",
        "outputId": "c035c416-81af-4b5d-a608-1087bc964f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVeWcobofkBF",
        "outputId": "d313be1a-5809-4fbf-dc86-8223223b0475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT-Dx92e4_IG"
      },
      "outputs": [],
      "source": [
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DPpGljtghW5",
        "outputId": "9c35b399-2dff-40c2-acb8-335b699a560d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auVaZlR-ghnR",
        "outputId": "615c6683-9d85-4e2f-ce5a-dfcf259dfd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVboMW3UTdOp"
      },
      "source": [
        "#### Treinamento Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgSqVuHrQcla"
      },
      "source": [
        "A técnica de aprendizado federado foi desenvolvida inicialmente para o treinamento de redes neurais, por isso precisamos definir uma rede neural para podermos usá-la localmente e,  futuramente, comparar os  resultados do  modelos gerados localmente e federado.\n",
        "\n",
        "Esta próxima célula define uma função que monta uma rede neural convolucional simples, que usaremos na etapa de treinamento. A rede neural recebe como atributos: o formato dos dados de entrada (*input_shape*) e o numero de classes do problema (*num_classes*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WcxuXm3AK-n"
      },
      "outputs": [],
      "source": [
        "def define_model(input_shape,num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
        "  model.add(MaxPool2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPW2kMNcRtzX"
      },
      "source": [
        "Conforme explicado anteriormente,  após o pré-processamento,  cada imagem do *dataset* terá o seguinte formato: 28 pixeis verticais, 28 pixeis horizontais e 1 canal de cor. Desta forma o formato de entrada dos dados é (28, 28, 1).\n",
        "\n",
        "Temos digitos de 0 a 9 em nosso *dataset*, ou seja, 10 possiveis classes. Com isso instanciamos uma rede neural usando a função *define_model* na variavel model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GycOgcz7JFs"
      },
      "outputs": [],
      "source": [
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "\n",
        "model = define_model(input_shape,num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0VpTq8oShd4"
      },
      "source": [
        "Inicialmente treinaremos a rede neural localmente para termos um *baseline* de comparação. A rede neural  é treinada por 5 épocas, usando 10% do *dataset* de treino para validação durante o treinamento.\n",
        "\n",
        "Usamos 64 como *batch_size*, isso significa que  expomos a rede neural a 64 amostras (lote, ou *batch*) antes de atualizarmos o valor da função de perda. Esse processo  é repetido até que todas as amostras tenham sido expostas à rede neural, terminando uma época de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWO0dJa7VL-",
        "outputId": "6e32da0f-b46b-43e2-95c7-ec90db12f3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 44s 52ms/step - loss: 0.2195 - accuracy: 0.9339 - val_loss: 0.1013 - val_accuracy: 0.9688\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 31s 37ms/step - loss: 0.0819 - accuracy: 0.9756 - val_loss: 0.0611 - val_accuracy: 0.9830\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 32s 38ms/step - loss: 0.0541 - accuracy: 0.9841 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 35s 41ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.0480 - val_accuracy: 0.9860\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 32s 38ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0529 - val_accuracy: 0.9853\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64 # lote\n",
        "epochs = 5 # época\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WftT7AFCSud_"
      },
      "source": [
        "Como conclusão, com o conjunto de teste usado neste laboratório, e usando  o nosso modelo,  obtivemos uma acurácia de ~98,39%, que é um resultado aceitável com relação a este *dataset*, comparando-se com os resultados de referência encontrados na literatura. Ver [referência](https://paperswithcode.com/sota/image-classification-on-mnist)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXIiIk8d7eGS",
        "outputId": "669128c0-09fc-4b67-e1dc-9936c9b69b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0492 - accuracy: 0.9838\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1XwzYWTiOa"
      },
      "source": [
        "#### Treinamento Federado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dPiK8tVRn1"
      },
      "source": [
        "Agora começaremos o treinamento federado desta mesma rede neural usando a biblioteca *flower*. Esta biblioteca implementa a arquitetura de aprendizado federado, onde no treinamento temos dois agentes: o servidor e os clientes.\n",
        "\n",
        "* Os clientes (treinadores) têm como tarefa treinar seus modelos usando seus dados locais e, após o treinamento, enviar os pesos encontrados para o servidor de agregação. Quando receberem os pesos agregados pelo servidor, os clientes atualizam seus modelos locai com estes pesos e recomeçam o treinamento, assim iniciando uma nova rodada (época).\n",
        "* O servidor de agregação, por sua vez, recebe estes pesos e usa algum algoritmo para agregar os diferentes pesos dos modelos gerados pelos clientes treinadores. Em seguida o servidor deve enviar de volta os pesos agregados para os clientes.\n",
        "\n",
        "Ao final desse processo,  os  pesos agregados representam o modelo global que está sendo treinado por esse conjunto de treinadores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTwlQHH6W5Fa"
      },
      "source": [
        "Sabendo disso, para o uso da biblioteca *flower* temos, como primeiro passo, que implementar o código dos clientes. Para isso definimos uma classe cliente que herda da super classe *NumPyClient* provida pela biblioteca *numpy*. Para seu uso temos que implementar obrigatoriamente 3 métodos em nosso cliente:\n",
        "\n",
        "\n",
        "1.  *get_parameters(self, config)*: este método recebe um dicionário de configuração e é chamado pelo servidor como um procedimento remoto. Ele retorna os pesos do modelo do cliente na rodada atual.\n",
        "2.  *fit(self, parameters, config)*: por este método, chamado via RPC pelo servidor, o cliente recebe os pesos do modelo global e um dicionário de configuração. Ele realiza o treinamento do modelo, primeiro setando os pesos do modelo com os recebidos pelo cliente do servidor e depois treinando um novo modelo com esses novos pesos iniciais. Ela retorna: os pesos encontrados após essa rodada de treinamento, o tamanho do conjunto de treinamento e um dicionário de métricas de avaliação do modelo. O dicionário pode ser retornado vazio.\n",
        "3.  *evaluate(self, parameters, config)*: por este método, chamado remotamente pelo servidor, o cliente recebe os pesos do modelo global e um dicionário de configuração. Ele avalia localmente o modelo treinado e retorna o valor da função de perda encontrado para este cliente, o tamanho do conjunto de teste e um dicionário de métricas de avaliação do modelo. Neste caso, retornaremos a acurácia.\n",
        "\n",
        "Também definimos um método opcional *\\_\\_init\\_\\_(self, model, x_train, y_train, x_test, y_test)* que é o de inicialização do objeto, recebendo o modelo pré-instanciado e os conjuntos de teste e treino.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9mL7lqLWQTG"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_test, y_test) -> None:\n",
        "        self.model = model\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=2)\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc = self.model.evaluate(self.x_test, self.y_test, verbose=2)\n",
        "        return loss, len(self.x_test), {\"accuracy\": acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkXB2eVJbeQk"
      },
      "source": [
        "Como estamos usando um *notebook*, não podemos instanciar clientes e servidores do *flower* diretamente. Por isso a biblioteca prove uma alternativa que é o módulo de simulação. Ele simula o aprendizado federado sem o uso de conexões de rede.\\\n",
        "\\\n",
        "Para o seu uso temos que definir uma função que instancias os clientes com a assinatura *fn(str) -> fl.client.Client*. Esta função recebe uma *string* que é um identificador único do cliente usado pela simulação e nos retorna o cliente instanciado. Internamente ela particiona o *dataset*, amostrando, sem reposição, um número aleatório de imagens, compondo um conjunto de dados que representa os dados locais daquele cliente.\n",
        "\n",
        "A seguir faremos os mesmos passos anteriores de pré-processamento e instanciamento da rede neural. Finalmente instanciaremos um cliente *flower* e retornamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHd05AShiI46"
      },
      "outputs": [],
      "source": [
        "def client_fn_random(cid: str) -> fl.client.Client:\n",
        "    input_shape = (28, 28, 1)\n",
        "    num_classes = 10\n",
        "    num_clients = 10\n",
        "    partition_size = 500\n",
        "\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    #sample_size_train = int(cid) * partition_size\n",
        "    #sample_size_test = int(cid) * partition_size\n",
        "    sample_size_train = int((1/num_clients)*len(x_train))\n",
        "    sample_size_test = int((1/num_clients)*len(x_test))\n",
        "    idx_train = np.random.choice(np.arange(len(x_train)), sample_size_train, replace=False)\n",
        "    x_train = x_train[idx_train]/255.0\n",
        "    y_train = y_train[idx_train]\n",
        "    y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "    idx_test = np.random.choice(np.arange(len(x_test)), sample_size_test, replace=False)\n",
        "    x_test = x_test[idx_test]/255.0\n",
        "    y_test = y_test[idx_test]\n",
        "    y_test = tf.one_hot(y_test.astype(np.int32), depth=10)\n",
        "    model = define_model(input_shape,num_classes)\n",
        "    # Create and return client\n",
        "    return FlowerClient(model, x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txp65BZCdFkD"
      },
      "source": [
        "Para a avaliação do modelo precisamos de uma função de agregação de métricas. Isto é necessário pois, a priori, a simulação não sabe que tipo de métrica será usada para avaliar o modelo. Por isso o programador tem que criar uma função que lide com a agregação dos valores de métricas que ele esta usando para avaliar seu modelo. Desta maneira esta função é usada para que a simulação consiga retornar a evolução dos valores das métricas em cada *round* usando um objeto do tipo *history*.\n",
        "\n",
        "\n",
        "Aqui definimos a função de agregação como a média ponderada da acurácia pelo tamanho do conjunto de dados de cada cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZZ0onPuExOM"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics):\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    acc = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    results = {\"accuracy\": sum(acc) / sum(examples)}\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VQnCBXtd0fr"
      },
      "source": [
        "Precisamos agora definir o número de clientes que participação do aprendizado federado, 10 clientes neste exemplo, e uma estratégia de agregação dos pesos a ser usada pelo servidor.\n",
        "\n",
        "Esta estratégia é um objeto do tipo *strategy* da biblioteca *flower*. Além de definir o algoritmo de agregação dos pesos, no caso usamos o *Federated Average (FedAvg)*, também é preciso configurar o comportamento do servidor durante o processo de treinamento. Com essa biblioteca nós configuramos o servidor para:\n",
        "\n",
        "1.   Escolher aleatoriamente 90% dos clientes (9 clientes neste exemplo) para o treinamento (*fraction_fit*);\n",
        "2.   Usar todos os clientes para a avaliação do modelo (*fraction_evaluate*);\n",
        "3.   Nunca usar menos que 9 clientes para o treinamento (*min_fit_clients*);\n",
        "4.   Nunca usar menos que 9 clientes para a avaliação do modelo (*min_evaluate_clients*);\n",
        "5.   Esperar que tenha pelo menos 9 clientes prontos antes de começar o treinamento(*min_available_clients*);\n",
        "6.   Usar a função *weighted_average*, definida anteriormente, como função de agregação de métricas\n",
        "\n",
        "Finalmente iniciamos a simulação usando a função *fl.simulation.start_simulation*. Passamos para essa função a função de instanciamento de clientes (*client_fn_random*), o número de clientes (*num_clients*), um dicionário de configuração, que diz para o servidor quantos *rounds* de treinamento queremos (*fl.server.ServerConfig(num_rounds=5)*) e a estratégia de treinamento (*strategy*).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRvT4OOdXADa",
        "outputId": "5b823ea6-c344-47ba-a1b7-58e30c4f642b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-07-03 23:07:46,490 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22576)\u001b[0m 32/32 - 1s - loss: 0.0533 - accuracy: 0.9850 - 1s/epoch - 45ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-03 23:07:52,352\tINFO worker.py:1636 -- Started a local Ray instance.\n",
            "INFO flwr 2023-07-03 23:07:54,184 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3896712806.0, 'memory': 7793425614.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 3896712806.0, 'memory': 7793425614.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-07-03 23:07:54,188 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-07-03 23:07:54,191 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "INFO flwr 2023-07-03 23:08:00,236 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-07-03 23:08:00,244 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-07-03 23:08:00,247 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-07-03 23:08:00,249 | server.py:218 | fit_round 1: strategy sampled 9 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 9 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 7s - loss: 0.4763 - accuracy: 0.8482 - 7s/epoch - 35ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 10s - loss: 0.4961 - accuracy: 0.8502 - 10s/epoch - 51ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 10s - loss: 0.5033 - accuracy: 0.8380 - 10s/epoch - 54ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.5068 - accuracy: 0.8422 - 7s/epoch - 37ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 7s - loss: 0.5048 - accuracy: 0.8407 - 7s/epoch - 37ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 10s - loss: 0.4782 - accuracy: 0.8490 - 10s/epoch - 52ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 10s - loss: 0.4870 - accuracy: 0.8503 - 10s/epoch - 53ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.5009 - accuracy: 0.8467 - 7s/epoch - 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:08:43,814 | server.py:232 | fit_round 1 received 9 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 9 results and 0 failures\n",
            "WARNING flwr 2023-07-03 23:08:43,862 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-07-03 23:08:43,868 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 6s - loss: 0.4975 - accuracy: 0.8465 - 6s/epoch - 32ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27147)\u001b[0m 32/32 - 1s - loss: 0.2488 - accuracy: 0.9290 - 1s/epoch - 45ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27148)\u001b[0m 32/32 - 1s - loss: 0.2609 - accuracy: 0.9330 - 1s/epoch - 45ms/step\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:08:54,429 | server.py:182 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:08:54,436 | server.py:218 | fit_round 2: strategy sampled 9 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 9 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27148)\u001b[0m 32/32 - 1s - loss: 0.2531 - accuracy: 0.9240 - 1s/epoch - 33ms/step\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.2522 - accuracy: 0.9228 - 7s/epoch - 39ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 9s - loss: 0.2568 - accuracy: 0.9253 - 9s/epoch - 45ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 9s - loss: 0.2500 - accuracy: 0.9248 - 9s/epoch - 45ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 9s - loss: 0.2407 - accuracy: 0.9278 - 9s/epoch - 47ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:09:38,277 | server.py:232 | fit_round 2 received 9 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:09:38,372 | server.py:168 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 6s - loss: 0.2597 - accuracy: 0.9183 - 6s/epoch - 29ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27147)\u001b[0m 32/32 - 1s - loss: 0.1580 - accuracy: 0.9500 - 714ms/epoch - 22ms/step\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:09:46,816 | server.py:182 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:09:46,822 | server.py:218 | fit_round 3: strategy sampled 9 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 9 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 9s - loss: 0.1890 - accuracy: 0.9448 - 9s/epoch - 49ms/step\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1986 - accuracy: 0.9430 - 7s/epoch - 36ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 10s - loss: 0.1912 - accuracy: 0.9440 - 10s/epoch - 53ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1859 - accuracy: 0.9450 - 7s/epoch - 37ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:10:31,099 | server.py:232 | fit_round 3 received 9 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:10:31,145 | server.py:168 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1845 - accuracy: 0.9470 - 7s/epoch - 38ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27147)\u001b[0m 32/32 - 1s - loss: 0.1239 - accuracy: 0.9640 - 758ms/epoch - 24ms/step\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:10:38,880 | server.py:182 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:10:38,888 | server.py:218 | fit_round 4: strategy sampled 9 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 9 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 10s - loss: 0.1489 - accuracy: 0.9525 - 10s/epoch - 54ms/step\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1504 - accuracy: 0.9533 - 7s/epoch - 37ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 11s - loss: 0.1572 - accuracy: 0.9503 - 11s/epoch - 57ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1487 - accuracy: 0.9547 - 7s/epoch - 38ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:11:23,591 | server.py:232 | fit_round 4 received 9 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:11:23,629 | server.py:168 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 6s - loss: 0.1334 - accuracy: 0.9570 - 6s/epoch - 33ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27148)\u001b[0m 32/32 - 1s - loss: 0.0834 - accuracy: 0.9740 - 746ms/epoch - 23ms/step\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:11:30,948 | server.py:182 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:11:30,955 | server.py:218 | fit_round 5: strategy sampled 9 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 9 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27147)\u001b[0m 188/188 - 10s - loss: 0.1282 - accuracy: 0.9617 - 10s/epoch - 55ms/step\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 7s - loss: 0.1276 - accuracy: 0.9587 - 7s/epoch - 36ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 10s - loss: 0.1186 - accuracy: 0.9653 - 10s/epoch - 52ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 8s - loss: 0.1306 - accuracy: 0.9630 - 8s/epoch - 41ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:12:15,165 | server.py:232 | fit_round 5 received 9 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-07-03 23:12:15,203 | server.py:168 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=27148)\u001b[0m 188/188 - 5s - loss: 0.1173 - accuracy: 0.9633 - 5s/epoch - 27ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27147)\u001b[0m 32/32 - 1s - loss: 0.0927 - accuracy: 0.9720 - 735ms/epoch - 23ms/step\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-07-03 23:12:22,321 | server.py:182 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "INFO flwr 2023-07-03 23:12:22,331 | server.py:147 | FL finished in 262.08186053899954\n",
            "INFO:flwr:FL finished in 262.08186053899954\n",
            "INFO flwr 2023-07-03 23:12:22,336 | app.py:218 | app_fit: losses_distributed [(1, 0.23879646211862565), (2, 0.1592353641986847), (3, 0.11766654253005981), (4, 0.09681472331285476), (5, 0.0901201270520687)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.23879646211862565), (2, 0.1592353641986847), (3, 0.11766654253005981), (4, 0.09681472331285476), (5, 0.0901201270520687)]\n",
            "INFO flwr 2023-07-03 23:12:22,342 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-07-03 23:12:22,343 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.9341000020503998), (2, 0.9564999997615814), (3, 0.9671999990940094), (4, 0.9700999915599823), (5, 0.9731000006198883)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.9341000020503998), (2, 0.9564999997615814), (3, 0.9671999990940094), (4, 0.9700999915599823), (5, 0.9731000006198883)]}\n",
            "INFO flwr 2023-07-03 23:12:22,345 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-07-03 23:12:22,347 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        }
      ],
      "source": [
        "num_clients = 10\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.9,\n",
        "    fraction_evaluate=1,\n",
        "    min_fit_clients=9,\n",
        "    min_evaluate_clients=9,\n",
        "    min_available_clients=int(\n",
        "        num_clients * 0.9\n",
        "    ),\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_random,\n",
        "    num_clients=num_clients,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjQznojrgy46"
      },
      "source": [
        "Printamos os resultados do treinamento retornados no formato do objeto *history*. Ele tem dois atributos: um dicionário com a média da função de perda a cada *round* e um dicionário com os valores das métricas agregadas a cada *round*, calculadas pela função de agregação.\n",
        "\n",
        "Podemos observar a evolução destes dois valores a cada *round*. Para os 4 primeiros *rounds* tivemos uma melhora do valor da função de perda e da acurácia, mas no último *round* a função de perda diminuiu pouco e a acurácia se manteve estável.\n",
        "\n",
        "O número de *rounds* de treinamento é um valor muito importante para o aprendizado federado. Similar ao número de épocas de treinamento no aprendizado local, precisamos de *rounds* suficientes para que o modelo convirja com pesos adequados, mas temos que tomar cuidado para não causar o *overfitting* da rede, caso tenhamos muitos *rounds*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLw296UPIIIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2551754-4110-4ea5-baed-45f60846d302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History (loss, distributed):\n",
            "\tround 1: 0.23879646211862565\n",
            "\tround 2: 0.1592353641986847\n",
            "\tround 3: 0.11766654253005981\n",
            "\tround 4: 0.09681472331285476\n",
            "\tround 5: 0.0901201270520687\n",
            "History (metrics, distributed, evaluate):\n",
            "{'accuracy': [(1, 0.9341000020503998), (2, 0.9564999997615814), (3, 0.9671999990940094), (4, 0.9700999915599823), (5, 0.9731000006198883)]}\n"
          ]
        }
      ],
      "source": [
        "print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbSgu-8-lDm5"
      },
      "source": [
        "A seguir plotaremos a acurácia por *round*. Observe que ela parece estar tendendo a aumentar a cada *round* e, **talvez**, se aumentássemos o numero de *rounds* teríamos uma acurácia ainda melhor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0OJfjkxW9NX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "750ed993-88e9-4721-e240-f77322864c98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(*zip(*history.metrics_distributed['accuracy']))\n",
        "plt.xlabel(\"Rounds\")\n",
        "plt.title(\"Acurácia por Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.scatter(*zip(*history.metrics_distributed['accuracy']), color='red')\n",
        "plt.xticks(np.arange(1, 6, 1.0))\n",
        "plt.yticks(np.arange(0.9, 1.0, 0.01))\n",
        "plt.xlim(1, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R6RJStQTnCc"
      },
      "source": [
        "#### Atividades\n",
        "\n",
        "Além dos códigos, deve-se entregar um relatório com  a discussão dos resultados para cada atividade.   Utilize o template da SBC para artigos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Atividade 1**\n",
        "\n",
        "Durante a configuração do treinamento federado definimos valores para muitos hyper-parâmetros. Um dos mais importantes foi o número de *rounds*. Por isso nesta tarefa vocês deverão treinar a rede de maneira federada variando o número de rounds em diferentes valores.\n",
        "\n",
        "\n",
        "\n",
        "*   Os valores a serem usados para o número de *rounds* são 10, 15, 20;\n",
        "*   Para cada valor deve-se plotar um gráfico de linha que relaciona o número de *rounds* com a acurácia obtida naquele número de *rounds*.\n",
        "\n",
        "Além   disso deve-se comparar a desempenho do modelo federado com os diferentes valores de *rounds* e o  desempenho encontrado quando treinamos localmente a rede neural.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n8LqayNw6xLV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjhS4hFxPoBt"
      },
      "source": [
        "**Atividade 2**\n",
        "\n",
        "Fizemos o aprendizado federado mediado por uma simulação, mas em um cenário real teríamos processos clientes, representando os treinadores, sendo executados em várias máquinas independentes, conectadas a um processo servidor (agregador) pela rede ou pela Internet, por exemplo.\n",
        "\n",
        "Como tarefa para casa deve-se  realizar o aprendizado federado de uma maneira mais próxima da realidade, usando processos diferentes para rodar os clientes e o servidor.\n",
        "\n",
        "Para isso será necessário criar 2 programas python, o *client.py* e o *server.py*:\n",
        "\n",
        "\n",
        "*   O *client.py* deve implementar uma classe que herda a classe  *NumpyClient*, fornecida pela biblioteca flower, instanciar um objeto dessa classe e se conectar ao servidor;\n",
        "*   O *server.py* deve configurar um servidor de aprendizado federado usando um objeto *strategy* e um objeto *serverConfigserverConfig*. Em seguida deve-se iniciar o servidor para realizar o aprendizado com (no mínimo) 5 clientes.\n",
        "\n",
        "O *server.py* e o *client.py* devem ser executados em terminais próprios. Isto é, deve se usar um minimo de  6 terminais na solução dessa tarefa: um para o  servidor e um para cada cliente (5 no mínimo).\n",
        "\n",
        "Ao final, plotar a acurácia para 2,5, 10, 20 e 40 *rounds* como a quantidade de clientes definida por você (mínimo  5).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dicas:\n",
        "\n",
        "\n",
        "\n",
        "*   Não é necessário utilizar várias máquinas para isso;\n",
        "\n",
        "*    Nesta atividade podemos emular uma rede por meio da interface de rede *localhost* (IP: 127.0.0.1) onde os processos treinadores e servidores podem ser executados em terminais Linux separados conectando-se pelo endereço IP 127.0.0.1;\n",
        "*   Como referência, usem a [documentação da biblioteca *flower*](https://flower.dev/docs/) na Seção QuickStart tutorials: tensorflow\n",
        "\n"
      ],
      "metadata": {
        "id": "06-xKYJVd_t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Atividade 3**\\\n",
        "**Obrigatória apenas para a pós-graduação**\n",
        "\n",
        "Usamos até agora uma rede neural convolucional para gerar o modelo treinado, tanto localmente como de maneira federada, mas o treinamento federado pode ser realizado (teoricamente) com qualquer classe de rede neural.\n",
        "\n",
        "Nesta atividade vocês deverão definir pelo menos 2 redes neurais não convolucionais para resolver o problema de classificação de dígitos com o *dataset mnist* e comparar os resultados do treinamento local e federado para essas redes.\n",
        "\n",
        "Dicas:\n",
        "\n",
        "\n",
        "*   O treinamento federado pode ser feito tanto por simulação, como este laboratório, ou com os programas *client.py* e *server.py* feitos na atividade anterior.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DhW_2IZKVy15"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}